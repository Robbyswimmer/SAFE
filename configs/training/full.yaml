# Full Production Training Configuration
# For full-scale training with curriculum learning
name: "full"
description: "Full production training configuration with curriculum learning"

# Training parameters
num_epochs: 10  # Will be overridden by curriculum if enabled
batch_size: 8
gradient_accumulation_steps: 4

# Learning rates - production values
learning_rate_projector: 1e-4
learning_rate_adapter: 5e-5
weight_decay: 0.01
warmup_steps: 1000
max_grad_norm: 1.0

# Evaluation settings
eval_every_n_epochs: 2
max_eval_batches: 100  # Full evaluation
validation_frequency: 5

# Loss weights - optimized for exact phrasing
audio_loss_weight: 1.0
retention_loss_weight: 1.0
distillation_temperature: 3.0
fisher_weight: 0.1
retention_tolerance: 0.005  # Strict tolerance for production
audio_contrastive_weight: 0.0  # DISABLED: Temporarily off to focus on reranking & SCST
audio_contrastive_temperature: 0.07
audio_contrastive_answer_max_length: 64
audio_contrastive_metric_weight: 0.3
audio_contrastive_negative_threshold: 0.4
audio_contrastive_max_negatives: 32

# Generation parameters - increased candidates for better reranking
audio_num_beams: 5  # Reduced from 8 to save memory during eval
audio_num_return_sequences: 5  # Match beam count
audio_num_samples: 5  # Reduced from 8 (total 10 candidates instead of 16)
audio_sample_top_p: 0.9
audio_sample_temperature: 0.85
audio_length_penalty: 0.85

# Reranking weights - aggressive tuning for exact phrase matching
# NOTE: log-prob is negative (-5 to -1), so must be heavily down-weighted
audio_rerank_with_clap: true
audio_rerank_logprob_weight: 0.05  # CRITICAL: Reduced from 1.0 to prevent negative log-prob dominance
audio_rerank_clap_weight: 0.35
audio_rerank_ngram_weight: 1.5  # Increased from 0.7 - strong n-gram emphasis
audio_rerank_coverage_weight: 0.1
audio_rerank_cider_weight: 2.0  # Increased from 0.8 - strongest signal for exact phrasing
audio_rerank_spider_weight: 0.3  # Increased from 0.2
audio_rerank_tag_vocab: "configs/tags/audio_tag_vocab.txt"
audio_rerank_num_tags: 5
audio_rerank_tag_weight: 0.25

# Logging and saving
logging_steps: 100
save_steps: 5000
early_stopping_patience: 3

# Performance
expected_runtime_minutes: 120
compute_requirements: "high"

# Production settings
enable_wandb: true
compute_baseline_metrics: true
save_best_checkpoint: true
final_evaluation: true

# SCST Fine-tuning (auto-triggers after plateau for direct metric optimization)
enable_scst_finetune: true
scst_epochs: 2  # Conservative fine-tuning duration
scst_learning_rate: 5e-6  # Low LR for policy gradient stability
scst_num_samples: 3  # Multiple samples per input to reduce variance
scst_sample_top_p: 0.9
scst_sample_temperature: 0.85  # Match generation temperature
scst_reward_metric: "cider"  # Optimize for CIDEr (exact phrase matching)
scst_patience_epochs: 3  # Trigger after 3 epochs without improvement
scst_improvement_threshold: 0.001  # 0.1% improvement required to reset patience
