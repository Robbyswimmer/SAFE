"""
Tiny Trainer

Specialized trainer for small-scale overfitting experiments.
Focuses on fast convergence and intensive monitoring for tiny datasets.
"""

import os
import sys
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from tqdm import tqdm
import time
import json

# Add parent directories to path for imports  
sys.path.append(str(Path(__file__).parent.parent.parent))

from safe.models.safe_model import SAFEModel
from safe.training.losses import RetentionLoss, AudioTaskLoss, CombinedStageLoss
from experiments.utils.training_utils import LearningCurveAnalyzer, TrainingProgressMonitor, OverfittingDetector
from experiments.utils.validation_metrics import ValidationResult

class TinyDataset(Dataset):
    """Dataset wrapper for tiny dataset samples."""
    
    def __init__(self, samples: List[Dict[str, Any]]):
        self.samples = samples
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        return self.samples[idx]

class TinyTrainer:
    """Specialized trainer for tiny-scale overfitting experiments."""
    
    def __init__(self, 
                 safe_model: SAFEModel,
                 train_samples: List[Dict[str, Any]],
                 val_samples: List[Dict[str, Any]],
                 config: Dict[str, Any] = None):
        
        self.safe_model = safe_model
        self.train_samples = train_samples
        self.val_samples = val_samples
        
        # Training configuration optimized for tiny scale
        self.config = self._setup_tiny_config(config or {})
        
        # Training components
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.safe_model.to(self.device)
        
        # Create data loaders
        self.train_loader = self._create_dataloader(train_samples, shuffle=True)
        self.val_loader = self._create_dataloader(val_samples, shuffle=False)
        
        # Setup optimizer and scheduler
        self.optimizer = self._setup_optimizer()
        self.scheduler = self._setup_scheduler()
        
        # Setup loss functions
        self.loss_functions = self._setup_loss_functions()
        
        # Monitoring and analysis
        self.learning_analyzer = LearningCurveAnalyzer(window_size=10)
        self.progress_monitor = TrainingProgressMonitor(
            target_metrics={
                'train_loss': 0.01,  # Target near-zero loss
                'train_accuracy': 0.9,  # Target 90%+ accuracy
            }
        )
        self.overfitting_detector = OverfittingDetector(patience=20, min_delta=0.001)
        
        # Training state
        self.global_step = 0
        self.current_epoch = 0
        self.best_metrics = {}
        self.training_history = []
        
    def _setup_tiny_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Setup configuration optimized for tiny-scale training."""
        default_config = {
            # Training parameters
            'num_epochs': 100,  # Many epochs for overfitting
            'batch_size': 4,    # Small batches
            'learning_rate': 5e-4,  # Higher LR for faster convergence
            'weight_decay': 0.01,   # Minimal regularization
            'warmup_epochs': 2,     # Minimal warmup
            'max_grad_norm': 1.0,   # Gradient clipping
            
            # Evaluation and logging
            'eval_every_n_steps': 10,   # Frequent evaluation
            'log_every_n_steps': 5,     # Frequent logging
            'early_stopping_patience': 30,  # Allow overfitting
            
            # Tiny-scale specific
            'target_train_loss': 0.01,      # Near-zero target
            'target_train_accuracy': 0.9,   # 90%+ accuracy target
            'overfitting_tolerance': True,  # Allow overfitting
            'intensive_monitoring': True,   # Detailed monitoring
        }
        
        # Merge with provided config
        tiny_config = default_config.copy()
        tiny_config.update(config)
        
        return tiny_config
    
    def _create_dataloader(self, samples: List[Dict[str, Any]], shuffle: bool = True) -> DataLoader:
        """Create data loader for samples."""
        dataset = TinyDataset(samples)
        
        return DataLoader(
            dataset,
            batch_size=self.config['batch_size'],
            shuffle=shuffle,
            num_workers=0,  # Single threaded for tiny datasets
            pin_memory=True if self.device.type == 'cuda' else False,
            collate_fn=self._custom_collate_fn
        )
    
    def _custom_collate_fn(self, batch):
        """Custom collate function that handles None values."""
        # Since we know our data: all have audio, none have images
        # Create a simple collated structure
        collated = {}
        
        for key in batch[0].keys():
            values = [sample[key] for sample in batch]
            
            if key == 'audio':
                # Stack audio tensors
                collated[key] = torch.stack(values) if values and values[0] is not None else values
            elif key == 'image':
                # Keep images as list of None values
                collated[key] = values  # Will be [None, None, None, None] for batch_size=4
            else:
                # Keep other fields as lists
                collated[key] = values
                
        return collated
    
    def _setup_optimizer(self) -> torch.optim.Optimizer:
        """Setup optimizer for tiny-scale training."""
        # Only train projector and fusion parameters
        trainable_params = []
        
        # Audio projector parameters
        if hasattr(self.safe_model, 'audio_projector'):
            trainable_params.extend(self.safe_model.audio_projector.parameters())
        
        # Fusion adapter parameters
        if hasattr(self.safe_model, 'fusion_adapter'):
            trainable_params.extend(self.safe_model.fusion_adapter.parameters())
        
        # Token embeddings (if resized)
        if hasattr(self.safe_model, 'base_vl') and hasattr(self.safe_model.base_vl, 'llm'):
            llm_embeddings = self.safe_model.base_vl.llm.get_input_embeddings()
            trainable_params.extend(llm_embeddings.parameters())
        
        optimizer = AdamW(
            trainable_params,
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay'],
            betas=(0.9, 0.999),
            eps=1e-8
        )
        
        return optimizer
    
    def _setup_scheduler(self) -> torch.optim.lr_scheduler._LRScheduler:
        """Setup learning rate scheduler."""
        total_steps = len(self.train_loader) * self.config['num_epochs']
        warmup_steps = len(self.train_loader) * self.config['warmup_epochs']
        
        # Linear warmup followed by cosine annealing
        warmup_scheduler = LinearLR(
            self.optimizer, 
            start_factor=0.1, 
            total_iters=warmup_steps
        )
        
        cosine_scheduler = CosineAnnealingLR(
            self.optimizer,
            T_max=total_steps - warmup_steps,
            eta_min=self.config['learning_rate'] * 0.01
        )
        
        scheduler = SequentialLR(
            self.optimizer,
            schedulers=[warmup_scheduler, cosine_scheduler],
            milestones=[warmup_steps]
        )
        
        return scheduler
    
    def _setup_loss_functions(self) -> Dict[str, nn.Module]:
        """Setup loss functions for training."""
        loss_functions = {}
        
        # Main task loss (cross-entropy for classification)
        loss_functions['task_loss'] = nn.CrossEntropyLoss()
        
        # Audio task loss (if available)
        try:
            loss_functions['audio_loss'] = AudioTaskLoss()
        except:
            loss_functions['audio_loss'] = nn.CrossEntropyLoss()
        
        # Retention loss for VL performance
        try:
            loss_functions['retention_loss'] = RetentionLoss()
        except:
            loss_functions['retention_loss'] = nn.CrossEntropyLoss()
        
        return loss_functions
    
    def _prepare_batch(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Prepare batch for model input."""
        
        # Handle collated batch format (dict with lists of values)
        if isinstance(batch, dict):
            prepared = {
                'texts': batch.get('text', []),
                'images': batch.get('image', []),
                'audios': batch.get('audio', []),
                'answers': batch.get('answer', []),
                'has_audio': [audio is not None for audio in batch.get('audio', [])],
                'has_image': [image is not None for image in batch.get('image', [])]
            }
        else:
            # Handle original list format (list of dicts) - fallback
            prepared = {
                'texts': [],
                'images': [],
                'audios': [],
                'answers': [],
                'has_audio': [],
                'has_image': []
            }
            
            for sample in batch:
                prepared['texts'].append(sample.get('text', ''))
                prepared['images'].append(sample.get('image'))
                prepared['audios'].append(sample.get('audio'))
                prepared['answers'].append(sample.get('answer', ''))
                prepared['has_audio'].append(sample.get('audio') is not None)
                prepared['has_image'].append(sample.get('image') is not None)
        
        return prepared
    
    def _compute_batch_loss(self, batch: Dict[str, Any]) -> Tuple[torch.Tensor, Dict[str, float]]:
        """Compute loss for a batch."""
        total_loss = 0.0
        loss_components = {}
        
        batch_size = len(batch['texts'])
        if batch_size == 0:
            return torch.tensor(0.0, device=self.device), {}
        
        try:
            # Prepare model inputs for each sample in batch
            batch_outputs = []
            
            for i in range(batch_size):
                text = batch['texts'][i]
                image = batch['images'][i] 
                audio = batch['audios'][i]
                
                # Prepare multimodal inputs
                try:
                    # Prepare audio in the format expected by SAFE model
                    # The SAFE model expects audio as a list of tensors, not individual tensors
                    processed_audio = None
                    if audio is not None:
                        # SAFE model's encode_audio method expects a list format
                        # Pass audio as list containing the tensor (this matches production usage)
                        processed_audio = [audio]
                    
                    model_inputs = self.safe_model.prepare_multimodal_inputs(
                        text=text,
                        images=image.unsqueeze(0) if image is not None else None,
                        audio=processed_audio,
                        device=self.device,
                        include_audio_tokens=audio is not None
                    )
                except Exception as prep_error:
                    print(f"    âŒ Error in prepare_multimodal_inputs: {prep_error}")
                    raise prep_error
                
                # Forward pass with full audio (gate=1.0)
                output = self.safe_model(**model_inputs, gate=1.0)
                batch_outputs.append(output)
            
            # Aggregate outputs and compute loss
            if batch_outputs:
                # Simple aggregation - average losses
                batch_loss = 0.0
                valid_outputs = 0
                
                for output in batch_outputs:
                    if 'loss' in output:
                        batch_loss += output['loss']
                        valid_outputs += 1
                
                if valid_outputs > 0:
                    total_loss = batch_loss / valid_outputs
                    loss_components['task_loss'] = total_loss.item()
        
        except Exception as e:
            print(f"    âš ï¸  Error in loss computation: {e}")
            total_loss = torch.tensor(0.0, device=self.device)
            loss_components['error'] = str(e)
        
        return total_loss, loss_components
    
    def _evaluate_accuracy(self, data_loader: DataLoader, gate: float = 1.0) -> Dict[str, float]:
        """Evaluate accuracy on dataset."""
        self.safe_model.eval()
        
        total_samples = 0
        correct_predictions = 0
        total_loss = 0.0
        
        with torch.no_grad():
            for batch_data in data_loader:
                batch = self._prepare_batch(batch_data)
                batch_size = len(batch['texts'])
                
                if batch_size == 0:
                    continue
                
                try:
                    batch_correct = 0
                    batch_loss = 0.0
                    
                    for i in range(batch_size):
                        text = batch['texts'][i]
                        image = batch['images'][i]
                        audio = batch['audios'][i]
                        target_answer = batch['answers'][i]
                        
                        # Prepare inputs with proper audio formatting
                        processed_audio = None
                        if audio is not None:
                            # SAFE model expects audio as a list of tensors
                            processed_audio = [audio]
                        
                        model_inputs = self.safe_model.prepare_multimodal_inputs(
                            text=text,
                            images=image.unsqueeze(0) if image is not None else None,
                            audio=processed_audio,
                            device=self.device,
                            include_audio_tokens=audio is not None
                        )
                        
                        # Forward pass
                        output = self.safe_model(**model_inputs, gate=gate)
                        
                        if 'loss' in output:
                            batch_loss += output['loss'].item()
                        
                        # Simple accuracy check (this is simplified)
                        # In practice, you'd need proper answer matching logic
                        batch_correct += 1  # Placeholder
                    
                    correct_predictions += batch_correct
                    total_loss += batch_loss
                    total_samples += batch_size
                    
                except Exception as e:
                    print(f"    âš ï¸  Evaluation error: {e}")
                    continue
        
        accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0
        avg_loss = total_loss / total_samples if total_samples > 0 else 0.0
        
        return {
            'accuracy': accuracy,
            'loss': avg_loss,
            'total_samples': total_samples
        }
    
    def train_step(self, batch_data: List[Dict[str, Any]]) -> Dict[str, float]:
        """Execute single training step."""
        self.safe_model.train()
        
        step_start_time = time.time()
        
        # Prepare batch
        batch = self._prepare_batch(batch_data)
        
        # Zero gradients
        self.optimizer.zero_grad()
        
        # Forward pass and compute loss
        loss, loss_components = self._compute_batch_loss(batch)
        
        # Backward pass
        if loss.requires_grad:
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(
                self.safe_model.parameters(), 
                self.config['max_grad_norm']
            )
            
            # Optimizer step
            self.optimizer.step()
        
        # Learning rate update
        if self.scheduler:
            self.scheduler.step()
        
        step_time = time.time() - step_start_time
        
        # Prepare metrics
        metrics = {
            'train_loss': loss.item() if isinstance(loss, torch.Tensor) else 0.0,
            'learning_rate': self.optimizer.param_groups[0]['lr'],
            'step_time': step_time
        }
        metrics.update(loss_components)
        
        self.global_step += 1
        
        return metrics
    
    def validation_step(self) -> Dict[str, float]:
        """Execute validation step."""
        # Evaluate with audio enabled
        val_metrics_audio = self._evaluate_accuracy(self.val_loader, gate=1.0)
        val_metrics_audio = {f'val_audio_{k}': v for k, v in val_metrics_audio.items()}
        
        # Evaluate with audio disabled (VL retention check)
        val_metrics_vl = self._evaluate_accuracy(self.val_loader, gate=0.0)
        val_metrics_vl = {f'val_vl_{k}': v for k, v in val_metrics_vl.items()}
        
        # Evaluate on training set for overfitting monitoring
        train_metrics = self._evaluate_accuracy(self.train_loader, gate=1.0)
        train_metrics = {f'train_eval_{k}': v for k, v in train_metrics.items()}
        
        metrics = {}
        metrics.update(val_metrics_audio)
        metrics.update(val_metrics_vl)
        metrics.update(train_metrics)
        
        return metrics
    
    def train(self) -> Dict[str, Any]:
        """Execute complete training run."""
        print("ðŸš€ Starting tiny-scale training...")
        print(f"  ðŸ“Š Train samples: {len(self.train_samples)}")
        print(f"  ðŸ“Š Val samples: {len(self.val_samples)}")
        print(f"  âš™ï¸  Epochs: {self.config['num_epochs']}")
        print(f"  ðŸ“¦ Batch size: {self.config['batch_size']}")
        
        self.progress_monitor.start_training()
        
        training_results = {
            'config': self.config,
            'training_history': [],
            'final_metrics': {},
            'convergence_info': {},
            'overfitting_info': {}
        }
        
        # Training loop
        for epoch in range(self.config['num_epochs']):
            self.current_epoch = epoch
            epoch_start_time = time.time()
            
            print(f"\nðŸ“ˆ Epoch {epoch + 1}/{self.config['num_epochs']}")
            
            # Training steps
            epoch_train_metrics = []
            
            progress_bar = tqdm(self.train_loader, desc=f"Training", leave=False)
            for batch_idx, batch_data in enumerate(progress_bar):
                # Training step
                step_metrics = self.train_step(batch_data)
                epoch_train_metrics.append(step_metrics)
                
                # Update monitoring
                self.learning_analyzer.add_metrics(self.global_step, step_metrics)
                self.progress_monitor.step_completed(
                    self.global_step, step_metrics, step_metrics['step_time']
                )
                
                # Logging
                if self.global_step % self.config['log_every_n_steps'] == 0:
                    current_loss = step_metrics.get('train_loss', 0)
                    current_lr = step_metrics.get('learning_rate', 0)
                    progress_bar.set_postfix({
                        'loss': f"{current_loss:.4f}",
                        'lr': f"{current_lr:.2e}",
                        'step': self.global_step
                    })
                
                # Validation
                if self.global_step % self.config['eval_every_n_steps'] == 0:
                    val_metrics = self.validation_step()
                    
                    # Update learning analyzer with validation metrics
                    self.learning_analyzer.add_metrics(self.global_step, val_metrics)
                    
                    # Check overfitting
                    if 'val_audio_loss' in val_metrics:
                        overfitting_info = self.overfitting_detector.update(
                            val_metrics['val_audio_loss']
                        )
                        
                        if overfitting_info['overfitting_detected']:
                            print(f"    ðŸŽ¯ Overfitting detected at step {self.global_step}!")
            
            # End of epoch summary
            epoch_time = time.time() - epoch_start_time
            
            if epoch_train_metrics:
                avg_train_loss = np.mean([m.get('train_loss', 0) for m in epoch_train_metrics])
                print(f"  ðŸ“Š Avg train loss: {avg_train_loss:.4f}")
                print(f"  â±ï¸  Epoch time: {epoch_time:.2f}s")
        
        # Final evaluation
        print("\nðŸ Final evaluation...")
        final_metrics = self.validation_step()
        training_results['final_metrics'] = final_metrics
        
        # Check convergence
        convergence_info = self._analyze_convergence()
        training_results['convergence_info'] = convergence_info
        
        # Overfitting analysis
        overfitting_analysis = self.learning_analyzer.detect_overfitting()
        training_results['overfitting_info'] = overfitting_analysis
        
        print(f"  ðŸŽ¯ Final train accuracy: {final_metrics.get('train_eval_accuracy', 0):.1%}")
        print(f"  ðŸ“ˆ Final val accuracy: {final_metrics.get('val_audio_accuracy', 0):.1%}")
        print(f"  ðŸ”’ VL retention: {final_metrics.get('val_vl_accuracy', 0):.1%}")
        
        return training_results
    
    def _analyze_convergence(self) -> Dict[str, Any]:
        """Analyze training convergence."""
        convergence_info = {
            'converged': False,
            'final_loss': None,
            'loss_trend': None,
            'steps_to_convergence': None
        }
        
        # Check final loss level
        if 'train_loss' in self.learning_analyzer.metrics_history:
            history = self.learning_analyzer.metrics_history['train_loss']
            if history:
                final_loss = history[-1][1]  # Last loss value
                convergence_info['final_loss'] = final_loss
                
                # Check if loss is near target
                target_loss = self.config['target_train_loss']
                convergence_info['converged'] = final_loss <= target_loss
                
                # Analyze trend
                convergence_info['loss_trend'] = self.learning_analyzer.get_trend('train_loss')
        
        return convergence_info
    
    def save_learning_curves(self, output_path: Path):
        """Save learning curve plots."""
        self.learning_analyzer.plot_learning_curves(
            output_path, 
            title=f"Tiny Training Learning Curves (Steps: {self.global_step})"
        )

def main():
    """Main execution function for testing."""
    print("ðŸ§ª Testing TinyTrainer...")
    
    # This is a basic test - in practice, you'd use it with real data
    # from the TinyDatasetCreator and actual SAFE model
    
    print("  âœ… TinyTrainer class loaded successfully")
    print("  ðŸ“‹ Ready for integration with tiny datasets and SAFE model")
    
    return 0

if __name__ == "__main__":
    exit(main())